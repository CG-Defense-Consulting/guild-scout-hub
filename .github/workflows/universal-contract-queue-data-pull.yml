name: Universal Contract Queue Data Pull

on:
  # Manual trigger from GitHub UI
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force refresh even if data already exists'
        required: false
        type: boolean
        default: false
      headless:
        description: 'Run Chrome in headless mode'
        required: false
        type: boolean
        default: true
      timeout:
        description: 'Timeout for page operations in seconds'
        required: false
        type: number
        default: 30
      retry_attempts:
        description: 'Number of retry attempts for each operation'
        required: false
        type: number
        default: 3
      batch_size:
        description: 'Size of batches for database uploads'
        required: false
        type: number
        default: 50
      verbose:
        description: 'Enable verbose logging'
        required: false
        type: boolean
        default: false
      limit:
        description: 'Limit number of contracts to process (optional)'
        required: false
        type: number
        default: 0
  
  # Allow triggering via API/webhook
  repository_dispatch:
    types: [universal_contract_queue_data_pull]

jobs:
  pull-contract-data:
    runs-on: ubuntu-latest
    timeout-minutes: 90  # Increased timeout for comprehensive data pulling
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'
          
      - name: Set up Chrome
        uses: browser-actions/setup-chrome@v1
        
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip xvfb
          
      - name: Configure Chrome permissions
        run: |
          # Ensure Chrome can run in headless mode
          sudo mkdir -p /etc/opt/chrome/policies/managed/
          echo '{"CommandLineFlagSecurityWarningsEnabled": false}' | sudo tee /etc/opt/chrome/policies/managed/managed_policies.json
          
      - name: Verify Chrome installation
        run: |
          echo "Chrome version:"
          google-chrome --version || echo "Chrome not found in PATH"
          echo "Chrome binary location:"
          which google-chrome || echo "Chrome binary not found"
            
      - name: Setup ChromeDriver
        uses: ./.github/actions/setup-chromedriver
          
      - name: Test Chrome setup
        run: |
          # Test Chrome and ChromeDriver
          echo "=== Chrome Setup Verification ==="
          echo "Chrome version:"
          google-chrome --version
          echo ""
          echo "ChromeDriver version:"
          chromedriver --version
          echo ""
          echo "ChromeDriver location:"
          which chromedriver
          echo ""
          echo "ChromeDriver path contents:"
          ls -la /usr/local/bin/chromedriver* || echo "No ChromeDriver in /usr/local/bin"
          ls -la /usr/bin/chromedriver* || echo "No ChromeDriver in /usr/bin"
          echo ""
          echo "PATH environment:"
          echo $PATH
          
      - name: Set up environment variables
        run: |
          # Create .env file from GitHub secrets
          cat > etl/.env << EOF
          VITE_SUPABASE_URL=${{ secrets.VITE_SUPABASE_URL }}
          VITE_SUPABASE_PUBLISHABLE_KEY=${{ secrets.VITE_SUPABASE_PUBLISHABLE_KEY }}
          SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          DIBBS_BASE_URL=https://www.dibbs.bsm.dla.mil
          DIBBS_DOWNLOAD_DIR=./downloads
          SELENIUM_HEADLESS=true
          SELENIUM_TIMEOUT=30
          LOG_LEVEL=INFO
          LOG_FILE=./logs/etl.log
          SUPABASE_BUCKET_NAME=docs
          EOF
          
          # Export environment variables for Python to access
          # Use GITHUB_ENV to make them available to subsequent steps
          echo "VITE_SUPABASE_URL=${{ secrets.VITE_SUPABASE_URL }}" >> $GITHUB_ENV
          echo "VITE_SUPABASE_PUBLISHABLE_KEY=${{ secrets.VITE_SUPABASE_PUBLISHABLE_KEY }}" >> $GITHUB_ENV
          echo "SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" >> $GITHUB_ENV
          echo "DIBBS_BASE_URL=https://www.dibbs.bsm.dla.mil" >> $GITHUB_ENV
          echo "DIBBS_DOWNLOAD_DIR=./downloads" >> $GITHUB_ENV
          echo "SELENIUM_HEADLESS=true" >> $GITHUB_ENV
          echo "SELENIUM_TIMEOUT=30" >> $GITHUB_ENV
          echo "LOG_LEVEL=INFO" >> $GITHUB_ENV
          echo "LOG_FILE=./logs/etl.log" >> $GITHUB_ENV
          echo "SUPABASE_BUCKET_NAME=docs" >> $GITHUB_ENV
          
      - name: Install Python dependencies
        run: |
          cd etl
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Create necessary directories
        run: |
          cd etl
          mkdir -p downloads logs
          
      - name: Execute Universal Contract Queue Data Pull Workflow
        run: |
          cd etl
          
          # Build command arguments
          CMD_ARGS="python workflows/adhoc/universal_contract_queue_data_pull.py"
          
          # Add optional arguments
          if [ "${{ github.event.inputs.force_refresh }}" = "true" ]; then
            CMD_ARGS="$CMD_ARGS --force-refresh"
          fi
          
          if [ "${{ github.event.inputs.headless }}" = "false" ]; then
            CMD_ARGS="$CMD_ARGS --no-headless"
          fi
          
          if [ "${{ github.event.inputs.timeout }}" != "30" ]; then
            CMD_ARGS="$CMD_ARGS --timeout ${{ github.event.inputs.timeout }}"
          fi
          
          if [ "${{ github.event.inputs.retry_attempts }}" != "3" ]; then
            CMD_ARGS="$CMD_ARGS --retry-attempts ${{ github.event.inputs.retry_attempts }}"
          fi
          
          if [ "${{ github.event.inputs.batch_size }}" != "50" ]; then
            CMD_ARGS="$CMD_ARGS --batch-size ${{ github.event.inputs.batch_size }}"
          fi
          
          if [ "${{ github.event.inputs.verbose }}" = "true" ]; then
            CMD_ARGS="$CMD_ARGS --verbose"
          fi
          
          if [ "${{ github.event.inputs.limit }}" != "0" ]; then
            CMD_ARGS="$CMD_ARGS --limit ${{ github.event.inputs.limit }}"
          fi
          
          echo "Executing command: $CMD_ARGS"
          echo "Workflow will internally query universal_contract_queue to discover contracts needing processing"
          
          # Execute the workflow
          eval $CMD_ARGS
          
      - name: Upload workflow logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ucq-data-pull-logs
          path: |
            etl/logs/
            etl/downloads/
          retention-days: 7
          
      - name: Upload workflow results
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: ucq-data-pull-results
          path: |
            etl/workflow_results/
          retention-days: 30
          
      - name: Summary
        if: always()
        run: |
          echo "=== Universal Contract Queue Data Pull Workflow Summary ==="
          echo "Workflow: Universal Contract Queue Data Pull"
          echo "Status: ${{ job.status }}"
          echo "Data Discovery: Internal query of universal_contract_queue table"
          echo "Data Types Pulled:"
          echo "  - AMSC Codes (conditional)"
          echo "  - RFQ PDFs (conditional)"
          echo "  - Solicitation Open/Closed Status (conditional)"
          echo "Chrome Setup: Shared instance for all operations"
          echo "Conditional Logic: Applied based on existing data gaps"
          echo "Contract Selection: Automatically determined by workflow"
          echo "========================================================="
